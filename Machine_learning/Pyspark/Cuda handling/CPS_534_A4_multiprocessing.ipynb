{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QtkbaO4Hq60y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import json\n",
        "import copy\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import logging\n",
        "import random\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "def _make_layers(cfg):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for layer_cfg in cfg:\n",
        "        if layer_cfg == 'M':\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        else:\n",
        "            layers.append(nn.Conv2d(in_channels=in_channels,\n",
        "                                    out_channels=layer_cfg,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=True))\n",
        "            layers.append(nn.BatchNorm2d(num_features=layer_cfg))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            in_channels = layer_cfg\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class _VGG(nn.Module):\n",
        "    \"\"\"\n",
        "    VGG module for 3x32x32 input, 10 classes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name='VGG11'):\n",
        "        super(_VGG, self).__init__()\n",
        "        cfg = _cfg[name]\n",
        "        self.layers = _make_layers(cfg)\n",
        "        flatten_features = 512\n",
        "        self.fc1 = nn.Linear(flatten_features, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.layers(x)\n",
        "        y = y.view(y.size(0), -1)\n",
        "        y = self.fc1(y)\n",
        "        return y\n",
        "\n",
        "def VGG11():\n",
        "    return _VGG('VGG11')\n"
      ],
      "metadata": {
        "id": "cqS9OuSku8lv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.multiprocessing as mp\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.distributed import init_process_group, destroy_process_group"
      ],
      "metadata": {
        "id": "mHZSxWRH5BUR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ddp_setup(rank, world_size):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        rank: Unique identifier of each process\n",
        "        world_size: Total number of processes\n",
        "    \"\"\"\n",
        "    print(\"in ddp_setup\")\n",
        "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
        "    #init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
        "    # rank = torch.device(\"cuda:{}\".format(current_gpu_index))\n",
        "\n",
        "    torch.distributed.init_process_group(\n",
        "        backend=\"nccl\",\n",
        "        init_method=\"env://\",\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "    )\n",
        "    torch.cuda.set_device(rank)"
      ],
      "metadata": {
        "id": "yAYrVjD35gWw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"cpu\"\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "X7s6-ICC56dO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, gpu_id, train_loader, optimizer):\n",
        "        self.gpu_id = gpu_id\n",
        "        self.model = model.to(gpu_id)\n",
        "        self.model = DDP(model, device_ids=[gpu_id])\n",
        "        self.train_loader = train_loader\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def train(self, total_epochs):\n",
        "        for epoch in range(total_epochs):\n",
        "          self.train_model(epoch)\n",
        "        return None\n",
        "\n",
        "    def train_model(self, epoch):\n",
        "        epoch_startTime = dt.datetime.now()\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "            batch_startTime = dt.datetime.now()\n",
        "            data, target = data.to(self.gpu_id), target.to(self.gpu_id)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(data)\n",
        "\n",
        "            loss = torch.nn.CrossEntropyLoss()(outputs, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            msg_iteration = 20\n",
        "            if batch_idx % msg_iteration == msg_iteration-1:    # print every $msg_iteration mini-batches\n",
        "                batch_endTime = dt.datetime.now()\n",
        "                batch_time = \"{:.2f}\".format((batch_endTime - batch_startTime).total_seconds())\n",
        "                print(f'rank : {self.gpu_id} epoch : {epoch + 1} batch_no:{batch_idx + 1:5d} MeanLoss_last_{msg_iteration}_batches: {running_loss / msg_iteration:.3f} current_batch_time: {batch_time} secs')\n",
        "                if  self.gpu_id == 0 :\n",
        "                    ckp = self.model.module.state_dict()\n",
        "                    PATH = \"checkpoint.pt\"\n",
        "                    torch.save(ckp, PATH)\n",
        "                    print(f\"Training checkpoint saved at {PATH}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        epoch_endTime = dt.datetime.now()\n",
        "        epoch_time = \"{:.2f}\".format((epoch_endTime - epoch_startTime).total_seconds())\n",
        "        print(\"rank : \",{self.gpu_id},\"Time taken for epoch : \",epoch + 1,\" = \",epoch_time,\" secs\\n\" )\n",
        "\n",
        "        return None\n",
        ""
      ],
      "metadata": {
        "id": "3fAyYyvKHWaX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(rank, world_size):\n",
        "    print(\"in\")\n",
        "    ddp_setup(rank, world_size)\n",
        "    gpu_id = rank\n",
        "    batch_size = 256\n",
        "    normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
        "    transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "            ])\n",
        "\n",
        "    training_set = datasets.CIFAR10(root=\"./data\", train=True,\n",
        "                                                download=True, transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(training_set,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    sampler=DistributedSampler(training_set),\n",
        "                                                    shuffle=False,\n",
        "                                                    pin_memory=True)\n",
        "\n",
        "\n",
        "    # training_criterion = torch.nn.CrossEntropyLoss()\n",
        "    model = VGG11()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
        "    total_epochs = 20\n",
        "    trainer = Trainer(model, gpu_id, train_loader, optimizer)\n",
        "    trainer.train(total_epochs)\n",
        "\n",
        "    destroy_process_group()\n"
      ],
      "metadata": {
        "id": "7gGZ6-ZAuxws"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_gEUN4YbDsv",
        "outputId": "0311473c-fae1-4b33-c335-af83bd42d66a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    world_size = torch.cuda.device_count()\n",
        "    # mp.spawn(main, args=(world_size,), nprocs=world_size, join=True, start_method='fork')\n",
        "    mp.start_processes(main, args=(world_size,), nprocs=world_size, join=True, start_method='fork')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWId_GUIu1_D",
        "outputId": "f9716538-e8b5-4fd1-93b0-c0ce1cb7b342"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in\n",
            "in ddp_setup\n",
            "Files already downloaded and verified\n",
            "rank : 0 epoch : 1 batch_no:   20 MeanLoss_last_20_batches: 6.591 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:   40 MeanLoss_last_20_batches: 2.759 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:   60 MeanLoss_last_20_batches: 2.602 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:   80 MeanLoss_last_20_batches: 2.424 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:  100 MeanLoss_last_20_batches: 2.346 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:  120 MeanLoss_last_20_batches: 2.316 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:  140 MeanLoss_last_20_batches: 2.312 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:  160 MeanLoss_last_20_batches: 2.291 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 1 batch_no:  180 MeanLoss_last_20_batches: 2.296 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  1  =  32.76  secs\n",
            "\n",
            "rank : 0 epoch : 2 batch_no:   20 MeanLoss_last_20_batches: 2.175 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:   40 MeanLoss_last_20_batches: 2.123 current_batch_time: 0.07 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:   60 MeanLoss_last_20_batches: 2.102 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:   80 MeanLoss_last_20_batches: 2.045 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:  100 MeanLoss_last_20_batches: 2.033 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:  120 MeanLoss_last_20_batches: 1.996 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:  140 MeanLoss_last_20_batches: 1.969 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:  160 MeanLoss_last_20_batches: 1.977 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 2 batch_no:  180 MeanLoss_last_20_batches: 1.938 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  2  =  32.66  secs\n",
            "\n",
            "rank : 0 epoch : 3 batch_no:   20 MeanLoss_last_20_batches: 1.911 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:   40 MeanLoss_last_20_batches: 1.859 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:   60 MeanLoss_last_20_batches: 1.858 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:   80 MeanLoss_last_20_batches: 1.831 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:  100 MeanLoss_last_20_batches: 1.836 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:  120 MeanLoss_last_20_batches: 1.820 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:  140 MeanLoss_last_20_batches: 1.811 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:  160 MeanLoss_last_20_batches: 1.787 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 3 batch_no:  180 MeanLoss_last_20_batches: 1.784 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  3  =  31.60  secs\n",
            "\n",
            "rank : 0 epoch : 4 batch_no:   20 MeanLoss_last_20_batches: 1.746 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:   40 MeanLoss_last_20_batches: 1.730 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:   60 MeanLoss_last_20_batches: 1.717 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:   80 MeanLoss_last_20_batches: 1.677 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:  100 MeanLoss_last_20_batches: 1.658 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:  120 MeanLoss_last_20_batches: 1.643 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:  140 MeanLoss_last_20_batches: 1.618 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:  160 MeanLoss_last_20_batches: 1.603 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 4 batch_no:  180 MeanLoss_last_20_batches: 1.562 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  4  =  31.10  secs\n",
            "\n",
            "rank : 0 epoch : 5 batch_no:   20 MeanLoss_last_20_batches: 1.541 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:   40 MeanLoss_last_20_batches: 1.502 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:   60 MeanLoss_last_20_batches: 1.500 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:   80 MeanLoss_last_20_batches: 1.497 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:  100 MeanLoss_last_20_batches: 1.460 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:  120 MeanLoss_last_20_batches: 1.450 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:  140 MeanLoss_last_20_batches: 1.424 current_batch_time: 0.08 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:  160 MeanLoss_last_20_batches: 1.410 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 5 batch_no:  180 MeanLoss_last_20_batches: 1.434 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  5  =  32.45  secs\n",
            "\n",
            "rank : 0 epoch : 6 batch_no:   20 MeanLoss_last_20_batches: 1.356 current_batch_time: 0.07 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:   40 MeanLoss_last_20_batches: 1.338 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:   60 MeanLoss_last_20_batches: 1.337 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:   80 MeanLoss_last_20_batches: 1.337 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:  100 MeanLoss_last_20_batches: 1.287 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:  120 MeanLoss_last_20_batches: 1.298 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:  140 MeanLoss_last_20_batches: 1.267 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:  160 MeanLoss_last_20_batches: 1.242 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 6 batch_no:  180 MeanLoss_last_20_batches: 1.266 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  6  =  32.03  secs\n",
            "\n",
            "rank : 0 epoch : 7 batch_no:   20 MeanLoss_last_20_batches: 1.209 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:   40 MeanLoss_last_20_batches: 1.193 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:   60 MeanLoss_last_20_batches: 1.192 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:   80 MeanLoss_last_20_batches: 1.189 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:  100 MeanLoss_last_20_batches: 1.151 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:  120 MeanLoss_last_20_batches: 1.132 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:  140 MeanLoss_last_20_batches: 1.108 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:  160 MeanLoss_last_20_batches: 1.106 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 7 batch_no:  180 MeanLoss_last_20_batches: 1.110 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  7  =  30.98  secs\n",
            "\n",
            "rank : 0 epoch : 8 batch_no:   20 MeanLoss_last_20_batches: 1.062 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:   40 MeanLoss_last_20_batches: 1.047 current_batch_time: 0.08 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:   60 MeanLoss_last_20_batches: 1.046 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:   80 MeanLoss_last_20_batches: 1.033 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:  100 MeanLoss_last_20_batches: 1.013 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:  120 MeanLoss_last_20_batches: 0.987 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:  140 MeanLoss_last_20_batches: 0.980 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:  160 MeanLoss_last_20_batches: 0.965 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 8 batch_no:  180 MeanLoss_last_20_batches: 0.982 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  8  =  32.62  secs\n",
            "\n",
            "rank : 0 epoch : 9 batch_no:   20 MeanLoss_last_20_batches: 0.959 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:   40 MeanLoss_last_20_batches: 0.939 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:   60 MeanLoss_last_20_batches: 0.926 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:   80 MeanLoss_last_20_batches: 0.924 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:  100 MeanLoss_last_20_batches: 0.916 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:  120 MeanLoss_last_20_batches: 0.892 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:  140 MeanLoss_last_20_batches: 0.909 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:  160 MeanLoss_last_20_batches: 0.894 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 9 batch_no:  180 MeanLoss_last_20_batches: 0.888 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  9  =  32.63  secs\n",
            "\n",
            "rank : 0 epoch : 10 batch_no:   20 MeanLoss_last_20_batches: 0.850 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:   40 MeanLoss_last_20_batches: 0.842 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:   60 MeanLoss_last_20_batches: 0.849 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:   80 MeanLoss_last_20_batches: 0.838 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:  100 MeanLoss_last_20_batches: 0.825 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:  120 MeanLoss_last_20_batches: 0.811 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:  140 MeanLoss_last_20_batches: 0.831 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:  160 MeanLoss_last_20_batches: 0.791 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 10 batch_no:  180 MeanLoss_last_20_batches: 0.819 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  10  =  31.41  secs\n",
            "\n",
            "rank : 0 epoch : 11 batch_no:   20 MeanLoss_last_20_batches: 0.788 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:   40 MeanLoss_last_20_batches: 0.779 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:   60 MeanLoss_last_20_batches: 0.792 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:   80 MeanLoss_last_20_batches: 0.766 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:  100 MeanLoss_last_20_batches: 0.750 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:  120 MeanLoss_last_20_batches: 0.723 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:  140 MeanLoss_last_20_batches: 0.740 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:  160 MeanLoss_last_20_batches: 0.719 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 11 batch_no:  180 MeanLoss_last_20_batches: 0.752 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  11  =  30.99  secs\n",
            "\n",
            "rank : 0 epoch : 12 batch_no:   20 MeanLoss_last_20_batches: 0.743 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:   40 MeanLoss_last_20_batches: 0.706 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:   60 MeanLoss_last_20_batches: 0.704 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:   80 MeanLoss_last_20_batches: 0.701 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:  100 MeanLoss_last_20_batches: 0.675 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:  120 MeanLoss_last_20_batches: 0.683 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:  140 MeanLoss_last_20_batches: 0.692 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:  160 MeanLoss_last_20_batches: 0.661 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 12 batch_no:  180 MeanLoss_last_20_batches: 0.697 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  12  =  31.88  secs\n",
            "\n",
            "rank : 0 epoch : 13 batch_no:   20 MeanLoss_last_20_batches: 0.684 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:   40 MeanLoss_last_20_batches: 0.668 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:   60 MeanLoss_last_20_batches: 0.655 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:   80 MeanLoss_last_20_batches: 0.652 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:  100 MeanLoss_last_20_batches: 0.629 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:  120 MeanLoss_last_20_batches: 0.622 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:  140 MeanLoss_last_20_batches: 0.654 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:  160 MeanLoss_last_20_batches: 0.620 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 13 batch_no:  180 MeanLoss_last_20_batches: 0.643 current_batch_time: 0.07 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  13  =  31.89  secs\n",
            "\n",
            "rank : 0 epoch : 14 batch_no:   20 MeanLoss_last_20_batches: 0.633 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:   40 MeanLoss_last_20_batches: 0.604 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:   60 MeanLoss_last_20_batches: 0.615 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:   80 MeanLoss_last_20_batches: 0.604 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:  100 MeanLoss_last_20_batches: 0.582 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:  120 MeanLoss_last_20_batches: 0.579 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:  140 MeanLoss_last_20_batches: 0.617 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:  160 MeanLoss_last_20_batches: 0.570 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 14 batch_no:  180 MeanLoss_last_20_batches: 0.597 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  14  =  30.99  secs\n",
            "\n",
            "rank : 0 epoch : 15 batch_no:   20 MeanLoss_last_20_batches: 0.585 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:   40 MeanLoss_last_20_batches: 0.565 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:   60 MeanLoss_last_20_batches: 0.572 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:   80 MeanLoss_last_20_batches: 0.571 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:  100 MeanLoss_last_20_batches: 0.543 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:  120 MeanLoss_last_20_batches: 0.561 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:  140 MeanLoss_last_20_batches: 0.570 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:  160 MeanLoss_last_20_batches: 0.543 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 15 batch_no:  180 MeanLoss_last_20_batches: 0.566 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  15  =  31.18  secs\n",
            "\n",
            "rank : 0 epoch : 16 batch_no:   20 MeanLoss_last_20_batches: 0.559 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:   40 MeanLoss_last_20_batches: 0.534 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:   60 MeanLoss_last_20_batches: 0.555 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:   80 MeanLoss_last_20_batches: 0.535 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:  100 MeanLoss_last_20_batches: 0.515 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:  120 MeanLoss_last_20_batches: 0.516 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:  140 MeanLoss_last_20_batches: 0.551 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:  160 MeanLoss_last_20_batches: 0.505 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 16 batch_no:  180 MeanLoss_last_20_batches: 0.532 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  16  =  32.24  secs\n",
            "\n",
            "rank : 0 epoch : 17 batch_no:   20 MeanLoss_last_20_batches: 0.529 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:   40 MeanLoss_last_20_batches: 0.515 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:   60 MeanLoss_last_20_batches: 0.520 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:   80 MeanLoss_last_20_batches: 0.511 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:  100 MeanLoss_last_20_batches: 0.489 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:  120 MeanLoss_last_20_batches: 0.477 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:  140 MeanLoss_last_20_batches: 0.502 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:  160 MeanLoss_last_20_batches: 0.461 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 17 batch_no:  180 MeanLoss_last_20_batches: 0.499 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  17  =  31.16  secs\n",
            "\n",
            "rank : 0 epoch : 18 batch_no:   20 MeanLoss_last_20_batches: 0.478 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:   40 MeanLoss_last_20_batches: 0.481 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:   60 MeanLoss_last_20_batches: 0.489 current_batch_time: 0.08 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:   80 MeanLoss_last_20_batches: 0.476 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:  100 MeanLoss_last_20_batches: 0.465 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:  120 MeanLoss_last_20_batches: 0.455 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:  140 MeanLoss_last_20_batches: 0.502 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:  160 MeanLoss_last_20_batches: 0.446 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 18 batch_no:  180 MeanLoss_last_20_batches: 0.468 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  18  =  32.41  secs\n",
            "\n",
            "rank : 0 epoch : 19 batch_no:   20 MeanLoss_last_20_batches: 0.466 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:   40 MeanLoss_last_20_batches: 0.444 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:   60 MeanLoss_last_20_batches: 0.470 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:   80 MeanLoss_last_20_batches: 0.449 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:  100 MeanLoss_last_20_batches: 0.437 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:  120 MeanLoss_last_20_batches: 0.421 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:  140 MeanLoss_last_20_batches: 0.452 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:  160 MeanLoss_last_20_batches: 0.427 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 19 batch_no:  180 MeanLoss_last_20_batches: 0.436 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  19  =  32.00  secs\n",
            "\n",
            "rank : 0 epoch : 20 batch_no:   20 MeanLoss_last_20_batches: 0.452 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:   40 MeanLoss_last_20_batches: 0.437 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:   60 MeanLoss_last_20_batches: 0.437 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:   80 MeanLoss_last_20_batches: 0.425 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:  100 MeanLoss_last_20_batches: 0.425 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:  120 MeanLoss_last_20_batches: 0.401 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:  140 MeanLoss_last_20_batches: 0.428 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:  160 MeanLoss_last_20_batches: 0.395 current_batch_time: 0.05 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank : 0 epoch : 20 batch_no:  180 MeanLoss_last_20_batches: 0.414 current_batch_time: 0.06 secs\n",
            "Training checkpoint saved at checkpoint.pt\n",
            "rank :  {0} Time taken for epoch :  20  =  31.46  secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testing_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target)\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "-3uqOxiguxXI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing():\n",
        "    batch_size = 256\n",
        "    normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
        "    transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize])\n",
        "    test_set = datasets.CIFAR10(root=\"./data\", train=False,\n",
        "                                    download=True, transform=transform_test)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(test_set,\n",
        "                                              num_workers=2,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=False,\n",
        "                                                  pin_memory=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    training_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    test_model = VGG11()\n",
        "    test_model.to(device)\n",
        "\n",
        "    checkpoint = torch.load('checkpoint.pt')\n",
        "    test_model.load_state_dict(checkpoint)\n",
        "\n",
        "    testing_model(test_model, test_loader, training_criterion, device)\n",
        "\n",
        "testing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xKm_okQ_WyK",
        "outputId": "85015d67-baa8-4225-8082-f8c18d993c13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test set: Average loss: 0.5737, Accuracy: 8084/10000 (81%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}